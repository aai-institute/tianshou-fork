{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TCEkXj7LFe2"
      },
      "outputs": [],
      "source": [
        "# Remember to install tianshou first\n",
        "!pip install tianshou==0.4.8\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "Replay Buffer is a very common module in DRL implementations. In Tianshou, you can consider Buffer module as  as a specialized form of Batch, which helps you track all data trajectories and provide utilities such as sampling method besides the basic storage.\n",
        "\n",
        "There are many kinds of Buffer modules in Tianshou, two most basic ones are ReplayBuffer and VectorReplayBuffer. The later one is specially designed for parallelized environments (will introduce in tutorial L3)."
      ],
      "metadata": {
        "id": "xoPiGVD8LNma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usages"
      ],
      "metadata": {
        "id": "OdesCAxANehZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic usages as a batch\n",
        "Usually a buffer stores all the data in a batch with circular-queue style."
      ],
      "metadata": {
        "id": "fUbLl9T_SrTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tianshou.data import Batch, ReplayBuffer\n",
        "# a buffer is initialised with its maxsize set to 10 (older data will be discarded if more data flow in).\n",
        "print(\"========================================\")\n",
        "buf = ReplayBuffer(size=10)\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))\n",
        "\n",
        "# add 3 steps of data into ReplayBuffer sequentially\n",
        "print(\"========================================\")\n",
        "for i in range(3):\n",
        "  buf.add(Batch(obs=i, act=i, rew=i, done=0, obs_next=i + 1, info={}))\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))\n",
        "\n",
        "# add another 10 steps of data into ReplayBuffer sequentially\n",
        "print(\"========================================\")\n",
        "for i in range(3, 13):\n",
        "  buf.add(Batch(obs=i, act=i, rew=i, done=0, obs_next=i + 1, info={}))\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mocZ6IqZTH62",
        "outputId": "66cc4181-c51b-4a47-aacf-666b92b7fc52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "ReplayBuffer()\n",
            "maxsize: 10, data length: 0\n",
            "========================================\n",
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([0, 1, 2, 0, 0, 0, 0, 0, 0, 0]),\n",
            "    obs: array([0, 1, 2, 0, 0, 0, 0, 0, 0, 0]),\n",
            "    done: array([False, False, False, False, False, False, False, False, False,\n",
            "                 False]),\n",
            "    rew: array([0., 1., 2., 0., 0., 0., 0., 0., 0., 0.]),\n",
            "    obs_next: array([1, 2, 3, 0, 0, 0, 0, 0, 0, 0]),\n",
            ")\n",
            "maxsize: 10, data length: 3\n",
            "========================================\n",
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    obs: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    done: array([False, False, False, False, False, False, False, False, False,\n",
            "                 False]),\n",
            "    rew: array([10., 11., 12.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]),\n",
            "    obs_next: array([11, 12, 13,  4,  5,  6,  7,  8,  9, 10]),\n",
            ")\n",
            "maxsize: 10, data length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like Batch, ReplayBuffer supports concatenation, splitting, advanced slicing and indexing, etc."
      ],
      "metadata": {
        "id": "H8B85Y5yUfTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(buf[-1])\n",
        "print(buf[-3:])\n",
        "# Try more methods you find useful in Batch yourself."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOX-ADOPNeEK",
        "outputId": "f1a8ec01-b878-419b-f180-bdce3dee73e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch(\n",
            "    obs: array(9),\n",
            "    act: array(9),\n",
            "    rew: array(9.),\n",
            "    done: array(False),\n",
            "    obs_next: array(10),\n",
            "    info: Batch(),\n",
            "    policy: Batch(),\n",
            ")\n",
            "Batch(\n",
            "    obs: array([7, 8, 9]),\n",
            "    act: array([7, 8, 9]),\n",
            "    rew: array([7., 8., 9.]),\n",
            "    done: array([False, False, False]),\n",
            "    obs_next: array([ 8,  9, 10]),\n",
            "    info: Batch(),\n",
            "    policy: Batch(),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReplayBuffer can also be saved into local disk, still keeping track of the trajectories. This is extremely helpful in offline DRL settings."
      ],
      "metadata": {
        "id": "vqldap-2WQBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "_buf = pickle.loads(pickle.dumps(buf))"
      ],
      "metadata": {
        "id": "Ppx0L3niNT5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding reserved keys for buffer\n",
        "As I have explained, ReplayBuffer is specially designed to utilize the implementations of DRL algorithms. So, for convenience, we reserve certain seven reserved keys in Batch.\n",
        "\n",
        "*   `obs`\n",
        "*   `act`\n",
        "*   `rew`\n",
        "*   `done`\n",
        "*   `obs_next`\n",
        "*   `info`\n",
        "*   `policy`\n",
        "\n",
        "The meaning of these seven reserved keys are consistent with the meaning in [OPENAI Gym](https://gym.openai.com/). We would recommend you simply use these seven keys when adding batched data into ReplayBuffer, because\n",
        "some of them are tracked in ReplayBuffer (e.g. \"done\" value is tracked to help us determine a trajectory's start index and end index, together with its total reward and episode length.)\n",
        "\n",
        "```\n",
        "buf.add(Batch(......, extro_info=0)) # This is okay but not recommended.\n",
        "buf.add(Batch(......, info={\"extro_info\":0})) # Recommended.\n",
        "```\n"
      ],
      "metadata": {
        "id": "Eqezp0OyXn6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data sampling\n",
        "We keep a replay buffer in DRL for one purpose:\"sample data from it for training\". `ReplayBuffer.sample()` and `ReplayBuffer.split(..., shuffle=True)` can both fullfill this need."
      ],
      "metadata": {
        "id": "ueAbTspsc6jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buf.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5xnYOhrchDl",
        "outputId": "bcd2c970-efa6-43bb-8709-720d38f77bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Batch(\n",
              "     obs: array([10, 11,  4,  3,  8]),\n",
              "     act: array([10, 11,  4,  3,  8]),\n",
              "     rew: array([10., 11.,  4.,  3.,  8.]),\n",
              "     done: array([False, False, False, False, False]),\n",
              "     obs_next: array([11, 12,  5,  4,  9]),\n",
              "     info: Batch(),\n",
              "     policy: Batch(),\n",
              " ), array([0, 1, 4, 3, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trajectory tracking\n",
        "Compared to Batch, a unique feature of ReplayBuffer is that it can help you track the environment trajectories.\n",
        "\n",
        "First, let us simulate a situation, where we add three trajectories into the buffer. The last trajectory is still not finished yet."
      ],
      "metadata": {
        "id": "IWyaOSKOcgK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import False_\n",
        "buf = ReplayBuffer(size=10)\n",
        "# Add the first trajectory (length is 3) into ReplayBuffer\n",
        "print(\"========================================\")\n",
        "for i in range(3):\n",
        "  result = buf.add(Batch(obs=i, act=i, rew=i, done=True if i==2 else False, obs_next=i + 1, info={}))\n",
        "  print(result)\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))\n",
        "# Add the second trajectory (length is 5) into ReplayBuffer\n",
        "print(\"========================================\")\n",
        "for i in range(3, 8):\n",
        "  result = buf.add(Batch(obs=i, act=i, rew=i, done=True if i==7 else False, obs_next=i + 1, info={}))\n",
        "  print(result)\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))\n",
        "# Add the third trajectory (length is 5, still not finished) into ReplayBuffer\n",
        "print(\"========================================\")\n",
        "for i in range(8, 13):\n",
        "  result = buf.add(Batch(obs=i, act=i, rew=i, done=False, obs_next=i + 1, info={}))\n",
        "  print(result)\n",
        "print(buf)\n",
        "print(\"maxsize: {}, data length: {}\".format(buf.maxsize, len(buf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0qRb6HLfhLB",
        "outputId": "9bdb7d4e-b6ec-489f-a221-0bddf706d85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "(array([0]), array([0.]), array([0]), array([0]))\n",
            "(array([1]), array([0.]), array([0]), array([0]))\n",
            "(array([2]), array([3.]), array([3]), array([0]))\n",
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([0, 1, 2, 0, 0, 0, 0, 0, 0, 0]),\n",
            "    obs: array([0, 1, 2, 0, 0, 0, 0, 0, 0, 0]),\n",
            "    done: array([False, False,  True, False, False, False, False, False, False,\n",
            "                 False]),\n",
            "    rew: array([0., 1., 2., 0., 0., 0., 0., 0., 0., 0.]),\n",
            "    obs_next: array([1, 2, 3, 0, 0, 0, 0, 0, 0, 0]),\n",
            ")\n",
            "maxsize: 10, data length: 3\n",
            "========================================\n",
            "(array([3]), array([0.]), array([0]), array([3]))\n",
            "(array([4]), array([0.]), array([0]), array([3]))\n",
            "(array([5]), array([0.]), array([0]), array([3]))\n",
            "(array([6]), array([0.]), array([0]), array([3]))\n",
            "(array([7]), array([25.]), array([5]), array([3]))\n",
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([0, 1, 2, 3, 4, 5, 6, 7, 0, 0]),\n",
            "    obs: array([0, 1, 2, 3, 4, 5, 6, 7, 0, 0]),\n",
            "    done: array([False, False,  True, False, False, False, False,  True, False,\n",
            "                 False]),\n",
            "    rew: array([0., 1., 2., 3., 4., 5., 6., 7., 0., 0.]),\n",
            "    obs_next: array([1, 2, 3, 4, 5, 6, 7, 8, 0, 0]),\n",
            ")\n",
            "maxsize: 10, data length: 8\n",
            "========================================\n",
            "(array([8]), array([0.]), array([0]), array([8]))\n",
            "(array([9]), array([0.]), array([0]), array([8]))\n",
            "(array([0]), array([0.]), array([0]), array([8]))\n",
            "(array([1]), array([0.]), array([0]), array([8]))\n",
            "(array([2]), array([0.]), array([0]), array([8]))\n",
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    obs: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    done: array([False, False, False, False, False, False, False,  True, False,\n",
            "                 False]),\n",
            "    rew: array([10., 11., 12.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]),\n",
            "    obs_next: array([11, 12, 13,  4,  5,  6,  7,  8,  9, 10]),\n",
            ")\n",
            "maxsize: 10, data length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### episode length and rewards tracking\n",
        "Notice that `ReplayBuffer.add()` returns a tuple of 4 numbers every time it returns, meaning `(current_index, episode_reward, episode_length, episode_start_index)`. `episode_reward` and `episode_length` are valid only when a trajectory is finished. This might save developers some trouble.\n",
        "\n"
      ],
      "metadata": {
        "id": "dO7PWdb_hkXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Episode index management\n",
        "In the ReplayBuffer above, we can get access to any data step by indexing.\n"
      ],
      "metadata": {
        "id": "xbVc90z8itH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(buf)\n",
        "data = buf[6]\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mKwo54MjupY",
        "outputId": "9ae14a7e-908b-44eb-afec-89b45bac5961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReplayBuffer(\n",
            "    info: Batch(),\n",
            "    act: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    obs: array([10, 11, 12,  3,  4,  5,  6,  7,  8,  9]),\n",
            "    done: array([False, False, False, False, False, False, False,  True, False,\n",
            "                 False]),\n",
            "    rew: array([10., 11., 12.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]),\n",
            "    obs_next: array([11, 12, 13,  4,  5,  6,  7,  8,  9, 10]),\n",
            ")\n",
            "Batch(\n",
            "    obs: array(6),\n",
            "    act: array(6),\n",
            "    rew: array(6.),\n",
            "    done: array(False),\n",
            "    obs_next: array(7),\n",
            "    info: Batch(),\n",
            "    policy: Batch(),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we know that step \"6\" is not the start of an episode (it should be step 4, 4-7 is the second trajectory we add into the ReplayBuffer), we wonder what is the earliest index of the that episode.\n",
        "\n",
        "This may seem easy but actually it is not. We cannot simply look at the \"done\" flag now, because we can see that since the third-added trajectory is not finished yet, step \"4\" is surrounded by flag \"False\". There are many things to consider. Things could get more nasty if you are using more advanced ReplayBuffer like VectorReplayBuffer, because now the data is not stored in a simple circular-queue.\n",
        "\n",
        "Luckily, all ReplayBuffer instances help you identify step indexes through a unified API."
      ],
      "metadata": {
        "id": "p5Co_Fmzj8Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for the previous index of index \"6\"\n",
        "now_index = 6\n",
        "while True:\n",
        "  prev_index = buf.prev(now_index)\n",
        "  print(prev_index)\n",
        "  if prev_index == now_index:\n",
        "    break\n",
        "  else:\n",
        "    now_index = prev_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcJ0LEX6mxHg",
        "outputId": "7830f5fb-96d9-4298-d09b-24e64b2f633c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "4\n",
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `ReplayBuffer.prev()`, we know that the earliest step of that episode is step \"3\". Similarly, `ReplayBuffer.next()` helps us indentify the last index of an episode regardless of which kind of ReplayBuffer we are using."
      ],
      "metadata": {
        "id": "4Wlb57V4lQyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# next step of indexes [4,5,6,7,8,9] are:\n",
        "print(buf.next([4,5,6,7,8,9]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl5TRMo7oOy5",
        "outputId": "4a11612c-3ee0-4e74-b028-c8759e71fbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 6 7 7 9 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also search for the indexes which are labeled \"done: False\", but are the last step in a trajectory."
      ],
      "metadata": {
        "id": "YJ9CcWZXoOXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(buf.unfinished_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkawk97NpItg",
        "outputId": "df10b359-c2c7-42ca-e50d-9caee6bccadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aforementioned APIs will be helpful when we calculate quantities like GAE and n-step-returns in DRL algorithms ([Example usage in Tianshou](https://github.com/thu-ml/tianshou/blob/6fc68578127387522424460790cbcb32a2bd43c4/tianshou/policy/base.py#L384)). The unified APIs ensure a modular design and a flexible interface."
      ],
      "metadata": {
        "id": "8_lMr0j3pOmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Reading\n",
        "## Other Buffer Module\n",
        "\n",
        "*   PrioritizedReplayBuffer, which helps you implement [prioritized experience replay](https://arxiv.org/abs/1511.05952)\n",
        "*   CachedReplayBuffer, one main buffer with several cached buffers (higher sample efficiency in some scenarios)\n",
        "*   ReplayBufferManager, A base class that can be inherited (may help you manage multiple buffers).\n",
        "\n",
        "Check the documentation and the source code for more details.\n",
        "\n",
        "## Support for steps stacking to use RNN in DRL.\n",
        "There is an option called `stack_num` (default to 1) when initialising the ReplayBuffer, which may help you use RNN in your algorithm. Check the documentation for details."
      ],
      "metadata": {
        "id": "FEyE0c7tNfwa"
      }
    }
  ]
}